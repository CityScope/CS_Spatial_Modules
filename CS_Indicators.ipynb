{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brix import Indicator, Handler\n",
    "import OpenCity\n",
    "import statsmodels\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import geopandas as gpd\n",
    "import urllib\n",
    "import json\n",
    "import requests\n",
    "import math\n",
    "import osmnx\n",
    "from shapely.geometry import Point, shape\n",
    "import datetime\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- make a base class for proximity and density indicators to elimate repetition\n",
    "- state only used for state.geom and subsetting thereof- really just need a shape file\n",
    "- relevant column names should be in a settings file\n",
    "- all US-specific functionality should be in OpenCity\n",
    "- may not need the buffere area graph because its a subset of the ref area graph\n",
    "- separate out functions for combining grid stats with zone stats- repeated in both indicators now\n",
    "- only consider interactive cells in updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_name='epa_test'\n",
    "geom_type='block_group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_geogrid(table_name):\n",
    "    \"\"\"\n",
    "    initialises the available types on the front-end to a default list from text file\n",
    "    initialises the GEOGRIDDATA to all \"None\"\n",
    "    \"\"\"\n",
    "    get_url='https://cityio.media.mit.edu/api/table/'+table_name\n",
    "    post_url='https://cityio.media.mit.edu/api/table/update/'+table_name\n",
    "    with urllib.request.urlopen(get_url+'/GEOGRID') as url:\n",
    "        geogrid=json.loads(url.read().decode())  \n",
    "    default_types=json.load(open('data/default_types.json'))\n",
    "    geogrid['properties']['types']=default_types\n",
    "\n",
    "    geogrid_data=[{\n",
    "                    \"color\": [0,0,0,0],\n",
    "                    \"height\": [0],\n",
    "                    \"id\": i,\n",
    "                    \"interactive\": \"Web\",\n",
    "                    \"name\": \"None\",\n",
    "                    \"tui_id\": None\n",
    "                    } for i in range(len(geogrid['features']))]\n",
    "\n",
    "    r = requests.post(post_url+'/GEOGRID', data = json.dumps(geogrid))\n",
    "    print('Initialise GEOGRID: {}'.format(r))\n",
    "\n",
    "    r = requests.post(post_url+'/GEOGRIDDATA', data = json.dumps(geogrid_data))\n",
    "    print('Initialise GEOGRIDDATA: {}'.format(r))\n",
    "    return geogrid['properties']\n",
    "    \n",
    "def identify_state(properties):\n",
    "    # TODO: if table already existed, just load state from text file\n",
    "    print('Downloading state outlines')\n",
    "    state_outlines=gpd.read_file(\n",
    "        'https://www2.census.gov/geo/tiger/TIGER2019/STATE/tl_2019_us_state.zip')\n",
    "    state_outlines=state_outlines.to_crs(\"EPSG:4326\")\n",
    "    table_lon, table_lat=properties['header']['longitude'], properties['header']['latitude']\n",
    "    table_Point=Point(table_lon, table_lat)\n",
    "    for ind, row in state_outlines.iterrows():\n",
    "        if row['geometry'].contains(table_Point):\n",
    "            return row['GEOID']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_types_over_grid(geogrid_data, side_length, type_def):\n",
    "    cell_area=side_length*side_length\n",
    "    aggregated={}  \n",
    "    for cell in geogrid_data:\n",
    "        name=cell['name']\n",
    "        type_info=type_def[name]\n",
    "        height=cell['height']\n",
    "        if isinstance(height, list):\n",
    "            height=height[-1]\n",
    "        if 'sqm_pperson' in type_info:\n",
    "            sqm_pperson=type_info['sqm_pperson']\n",
    "        else:\n",
    "            sqm_pperson=50\n",
    "        total_capacity=height*cell_area/sqm_pperson\n",
    "        if name in aggregated:\n",
    "            aggregated[name]+=total_capacity\n",
    "        else:\n",
    "            aggregated[name]=total_capacity\n",
    "    return aggregated\n",
    "\n",
    "def pop_one_cell(cell, side_length, type_def):\n",
    "    name=cell['name']\n",
    "    type_info=type_def[name]\n",
    "    height=cell['height']\n",
    "    cell_area=side_length*side_length\n",
    "    if isinstance(height, list):\n",
    "        height=height[-1]\n",
    "    if 'sqm_pperson' in type_info:\n",
    "        sqm_pperson=type_info['sqm_pperson']\n",
    "    else:\n",
    "        sqm_pperson=50\n",
    "    total_capacity=height*cell_area/sqm_pperson\n",
    "    if type_info['NAICS'] is None:\n",
    "        emp=0\n",
    "    else:\n",
    "        emp=total_capacity*sum(type_info['NAICS'].values())\n",
    "    if type_info['LBCS'] is None:\n",
    "        res=0\n",
    "    else:\n",
    "        res=total_capacity*sum([type_info['LBCS'][code] for code in type_info['LBCS'] if code.startswith('1')])\n",
    "    return res, emp\n",
    "    \n",
    "        \n",
    "\n",
    "def aggregate_attributes_over_grid(geogrid_data, attribute, side_length, type_def, digits=None):\n",
    "    # TODO: eliminate repetition with previous function\n",
    "    cell_area=side_length*side_length\n",
    "    aggregated={}\n",
    "    for cell in geogrid_data:\n",
    "        name=cell['name']\n",
    "        type_info=type_def[name]\n",
    "        if type_info[attribute] is not None:\n",
    "            height=cell['height']\n",
    "            if isinstance(height, list):\n",
    "                height=height[-1]\n",
    "            if 'sqm_pperson' in type_info:\n",
    "                sqm_pperson=type_info['sqm_pperson']\n",
    "            else:\n",
    "                sqm_pperson=50\n",
    "            total_capacity=height*cell_area/sqm_pperson\n",
    "            for code in type_info[attribute]:\n",
    "                if digits==None:\n",
    "                    code_digits=code\n",
    "                else:\n",
    "                    code_digits=code[0:digits]\n",
    "                add_capacity=total_capacity*type_info[attribute][code]\n",
    "                if code_digits in aggregated:\n",
    "                    aggregated[code_digits]+= add_capacity\n",
    "                else:\n",
    "                    aggregated[code_digits]= add_capacity\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_central_nodes(geodf, G):\n",
    "    \"\"\" takes a geodf and returns a list of nodes closest to their centroids\n",
    "    returns both the nearest nodes and the distance\n",
    "    \"\"\"\n",
    "    geodf_projected=osmnx.projection.project_gdf(geodf)\n",
    "    projected_centroids=geodf_projected['geometry'].centroid.values\n",
    "    projected_centroids_lst=[[c.x, c.y] for c in projected_centroids]\n",
    "    G_proj=osmnx.projection.project_graph(G, geodf_projected.crs)\n",
    "    G_proj_coordinates={node: [G_proj.nodes[node]['x'], G_proj.nodes[node]['y']] for node in G_proj.nodes}\n",
    "    node_order=[node for node in G_proj_coordinates]\n",
    "    nodes_kdtree=spatial.KDTree([G_proj_coordinates[node] for node in node_order])\n",
    "    dist, ind_nearest=nodes_kdtree.query(projected_centroids_lst)\n",
    "    nearest_nodes=[node_order[ind] for ind in ind_nearest]\n",
    "    return nearest_nodes, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proximity_Indicator(Indicator):\n",
    "    def load(self, state, table_name, buffer=1200):\n",
    "        self.zone_to_node_tolerance=500\n",
    "        self.grid_to_node_tolerance=100\n",
    "        self.table_name=table_name\n",
    "        self.buffer=buffer\n",
    "        self.state=state\n",
    "        self.get_geogrid()\n",
    "        self.get_overlap_geoids()\n",
    "#         self.G=self.get_network_around_geom_buffered(self.geogrid)\n",
    "        self.get_graph_reference_area()\n",
    "    \n",
    "        print('Getting central nodes')\n",
    "        zones_nearest_nodes, zones_nearest_dist= get_central_nodes(self.state.geom, self.ref_G)\n",
    "        self.state.geom['central_node']=zones_nearest_nodes\n",
    "        self.state.geom['nearest_dist']=zones_nearest_dist\n",
    "        \n",
    "        grid_nearest_nodes, grid_nearest_dist= get_central_nodes(self.geogrid, self.ref_G)\n",
    "        self.geogrid['central_node']=grid_nearest_nodes\n",
    "        self.geogrid['nearest_dist']=grid_nearest_dist\n",
    "#         self.state.geom['central_node']=osmnx.get_nearest_nodes(\n",
    "#             self.ref_G, self.state.geom['x_centroid'], self.state.geom['y_centroid'], method='balltree')\n",
    "#         self.geogrid['central_node']=osmnx.get_nearest_nodes(\n",
    "#             self.ref_G, self.geogrid['x_centroid'], self.geogrid['y_centroid'], method='balltree')\n",
    "        self.calculate_baseline_scores()\n",
    "        self.get_reachable_geoms_all_interactive()\n",
    "            \n",
    "    def get_geogrid(self):\n",
    "        get_url='https://cityio.media.mit.edu/api/table/'+self.table_name\n",
    "        with urllib.request.urlopen(get_url+'/GEOGRID') as url:\n",
    "            self.geogrid=gpd.read_file(url.read().decode())\n",
    "        centroids=self.geogrid['geometry'].centroid\n",
    "        self.geogrid['x_centroid']=[c.x for c in centroids]\n",
    "        self.geogrid['y_centroid']=[c.y for c in centroids]\n",
    "                       \n",
    "    def get_overlap_geoids(self):\n",
    "        \"\"\"\n",
    "        find the geoids of the baseline zones which overlap with hthe geogrid\n",
    "        \n",
    "        \"\"\"\n",
    "        self.state.geom['copy_GEOID']=self.state.geom.index\n",
    "        grid_intersect_zones=gpd.overlay(self.geogrid, self.state.geom, 'intersection')\n",
    "        self.overlapping_geoids=grid_intersect_zones['copy_GEOID'].unique()\n",
    "            \n",
    "    def make_ego_graph_around_geometry(self, zone, tolerance):\n",
    "        \"\"\"\n",
    "        For geometries within the buffered geogrid only.\n",
    "        Returns the graph within a walkable distance of the centre of the zone\n",
    "        \"\"\"\n",
    "        if zone['nearest_dist']<tolerance:\n",
    "            sub_graph = osmnx.graph.nx.ego_graph(self.ref_G, zone['central_node'], radius=1200, distance='length')\n",
    "        else:\n",
    "            sub_graph = osmnx.graph.nx.Graph()\n",
    "        return sub_graph\n",
    "    \n",
    "    def get_graph_reference_area(self):\n",
    "        self.state.subset_geom_by_distance(centre_x_y=[self.geogrid.x_centroid.mean(), self.geogrid.y_centroid.mean()], \n",
    "                                           radius=2500, name='reference')\n",
    "        reference_zones=self.state.return_geometry(subset_name='reference')\n",
    "        print('Downloading graph for reference area')\n",
    "        reference_zone_graph=self.get_network_around_geom_buffered(reference_zones)\n",
    "        self.ref_G=reference_zone_graph\n",
    "        \n",
    "    def calculate_baseline_scores(self):\n",
    "        # TODO: should use the get_reachable_geoms function?\n",
    "        print('Calculating baseline scores')\n",
    "        self.base_scores={'walkable_{}'.format(x): [] for x in [\n",
    "            'employment', 'housing', 'healthcare', 'hospitality', 'shopping']}\n",
    "        self.score_ecdfs={}\n",
    "        for ind, row in self.state.geom.loc[self.state.geom['reference']].iterrows():\n",
    "            # TODO: normalise each score by density at source?\n",
    "            sub_graph=self.make_ego_graph_around_geometry(row, tolerance=self.zone_to_node_tolerance)\n",
    "            sub_graph_nodes=sub_graph.nodes(data=False)\n",
    "            reachable_zones= list(self.state.geom.loc[\n",
    "                ((self.state.geom['central_node'].isin(list(sub_graph_nodes)))&\n",
    "                 (self.state.geom['nearest_dist']<self.zone_to_node_tolerance))\n",
    "                ].index.values)\n",
    "            stats_to_aggregate=['total_pop_rac', 'total_employ_wac']+[\n",
    "                col for col in self.state.geom.columns if (('naics' in col) or ('income' in col))]\n",
    "            reachable_area_attributes=self.state.geom.loc[reachable_zones][stats_to_aggregate].sum()\n",
    "            self.base_scores['walkable_employment'].append(reachable_area_attributes['total_employ_wac'])\n",
    "            self.base_scores['walkable_housing'].append(reachable_area_attributes['total_pop_rac'])\n",
    "            self.base_scores['walkable_healthcare'].append(reachable_area_attributes['emp_naics_62'])\n",
    "            self.base_scores['walkable_hospitality'].append(reachable_area_attributes['emp_naics_72'])\n",
    "            self.base_scores['walkable_shopping'].append(reachable_area_attributes['emp_naics_44-45'])\n",
    "        for score in self.base_scores:\n",
    "            base_scores_no_nan=[x for x in self.base_scores[score] if x==x]\n",
    "            self.score_ecdfs[score]=ECDF(base_scores_no_nan)\n",
    "            \n",
    "    def get_reachable_geoms(self, zone, tolerance):\n",
    "        \"\"\"\n",
    "        find all grid cells and all zones reachable from a geometry\n",
    "        \"\"\"\n",
    "        sub_graph=self.make_ego_graph_around_geometry(zone, tolerance)\n",
    "        sub_graph_nodes=sub_graph.nodes(data=False)\n",
    "        reachable_zones= list(self.state.geom.loc[\n",
    "                ((self.state.geom['central_node'].isin(list(sub_graph_nodes)))&\n",
    "                 (self.state.geom['nearest_dist']<self.zone_to_node_tolerance))\n",
    "                ].index.values)\n",
    "        reachable_grid_cells=list(self.geogrid.loc[\n",
    "                ((self.geogrid['central_node'].isin(list(sub_graph_nodes)))&\n",
    "                 (self.geogrid['nearest_dist']<self.grid_to_node_tolerance))\n",
    "                ].index.values)\n",
    "        return {'zones': reachable_zones, 'cells': reachable_grid_cells}\n",
    "    \n",
    "    def get_reachable_geoms_all_interactive(self):\n",
    "        \"\"\"\n",
    "        For every grid cell and every zone which intersects the grid:\n",
    "        find the reachable zones and reachable grid cells\n",
    "        \"\"\"\n",
    "        self.grid_to_reachable, self.zone_to_reachable={}, {}\n",
    "        for ind, row in self.geogrid.iterrows():\n",
    "            self.grid_to_reachable[ind]=self.get_reachable_geoms(row, self.grid_to_node_tolerance)\n",
    "        for ind, row in self.state.geom.loc[self.overlapping_geoids].iterrows():\n",
    "            self.zone_to_reachable[ind]=self.get_reachable_geoms(row, self.zone_to_node_tolerance)\n",
    "            \n",
    "    def aggregate_reachable_attributes_one_source(self, zones, cells, geogrid_data=None):\n",
    "        stats_to_aggregate=['total_pop_rac', 'total_employ_wac']+[\n",
    "                col for col in self.state.geom.columns if (('naics' in col) or ('income' in col))]\n",
    "        reachable_area_stats=dict(self.state.geom.loc[zones, stats_to_aggregate].sum())\n",
    "        if geogrid_data is not None:\n",
    "            geogrid_data_reachable=[geogrid_data[c] for c in cells]\n",
    "            side_length=self.get_table_properties()['cellSize']\n",
    "            type_def=geogrid_data.get_type_info()\n",
    "            agg_types=aggregate_types_over_grid(geogrid_data_reachable, side_length=side_length, type_def=type_def)\n",
    "            agg_naics=aggregate_attributes_over_grid(geogrid_data_reachable, 'NAICS', side_length=side_length, type_def=type_def, digits=2)\n",
    "            agg_lbcs=aggregate_attributes_over_grid(geogrid_data_reachable, 'LBCS', side_length=side_length, type_def=type_def, digits=1)\n",
    "            \n",
    "            # update total residential and total employment\n",
    "            add_emp=sum(agg_naics.values())\n",
    "            if '1' in agg_lbcs:\n",
    "                add_res=agg_lbcs['1']\n",
    "            else:\n",
    "                add_res=0    \n",
    "            reachable_area_stats['total_pop_rac']+=add_res\n",
    "            reachable_area_stats['total_employ_wac']+=add_emp\n",
    "            \n",
    "            # update employment for each NAICS code\n",
    "            for col in reachable_area_stats:\n",
    "                if 'naics' in col:\n",
    "                    col_naics_codes=col.split('naics_')[1].split('-')\n",
    "                    for code in col_naics_codes:\n",
    "                        if code in agg_naics:\n",
    "                            reachable_area_stats[col]+=agg_naics[code]                             \n",
    "            # update residential types\n",
    "            if 'Residential Low Income' in agg_types:\n",
    "                reachable_area_stats['res_income_u1250_rac']+=agg_types['Residential Low Income']\n",
    "            if 'Residential Med Income' in agg_types:\n",
    "                reachable_area_stats['res_income_1251-3333_rac']+=agg_types['Residential Med Income']\n",
    "            if 'Residential High Income' in agg_types:\n",
    "                reachable_area_stats['res_income_3333+_rac']+=agg_types['Residential High Income'] \n",
    "        return reachable_area_stats\n",
    "                \n",
    "    def aggregate_reachable_attributes_all_sources(self, geogrid_data=None):\n",
    "        zone_reachable_area_stats, grid_reachable_area_stats=[], []\n",
    "        for ind, row in self.state.geom.loc[self.overlapping_geoids].iterrows():\n",
    "            reachable_area_stats=self.aggregate_reachable_attributes_one_source(\n",
    "                self.zone_to_reachable[ind]['zones'], self.zone_to_reachable[ind]['cells'], geogrid_data)\n",
    "            reachable_area_stats['source_pop']=row['total_pop_rac']\n",
    "            reachable_area_stats['source_emp']=row['total_employ_wac']\n",
    "            reachable_area_stats['GEOID']=ind\n",
    "            zone_reachable_area_stats.append(reachable_area_stats)\n",
    "        if geogrid_data is not None:\n",
    "            side_length=self.get_table_properties()['cellSize']\n",
    "            type_def=geogrid_data.get_type_info()\n",
    "            for i_c, cell in enumerate(geogrid_data):\n",
    "                reachable_area_stats=self.aggregate_reachable_attributes_one_source(\n",
    "                    self.grid_to_reachable[i_c]['zones'], self.grid_to_reachable[i_c]['cells'], geogrid_data)\n",
    "                res, emp=pop_one_cell(cell, side_length, type_def)\n",
    "                reachable_area_stats['source_pop']=res\n",
    "                reachable_area_stats['source_emp']=emp\n",
    "                reachable_area_stats['id']=i_c\n",
    "                grid_reachable_area_stats.append(reachable_area_stats)\n",
    "        return zone_reachable_area_stats, grid_reachable_area_stats\n",
    "    \n",
    "    def compute_heatmaps(self, grid_reachable_area_stats):\n",
    "        max_scores={score: max(self.base_scores[score]) for score in self.base_scores}\n",
    "        features=[]\n",
    "        heatmap={'type': 'FeatureCollection',\n",
    "                 'properties': ['housing', 'employment', 'healthcare', 'hospitality', 'shopping']}\n",
    "        x_centroid_list, y_centroid_list=self.geogrid['x_centroid'], self.geogrid['y_centroid']\n",
    "        for i_c, cell_stats in enumerate(grid_reachable_area_stats):\n",
    "            features.append({\n",
    "              \"type\": \"Feature\",\n",
    "              \"properties\": [(cell_stats['total_pop_rac']/max_scores['walkable_housing'])**2, \n",
    "                             (cell_stats['total_employ_wac']/max_scores['walkable_employment'])**2,\n",
    "                             (cell_stats['emp_naics_62']/max_scores['walkable_healthcare'])**2, \n",
    "                             (cell_stats['emp_naics_72']/max_scores['walkable_hospitality'])**2, \n",
    "                             (cell_stats['emp_naics_44-45']/max_scores['walkable_shopping'])**2],\n",
    "              \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [\n",
    "                  x_centroid_list[i_c],\n",
    "                  y_centroid_list[i_c]\n",
    "                ]\n",
    "              }\n",
    "            })\n",
    "        heatmap['features']=features\n",
    "        return heatmap\n",
    "                 \n",
    "    def calculate_indicators(self, site_stats):\n",
    "        raw_ind={}\n",
    "        sum_all_source_pop=sum([s['source_pop'] for s in site_stats])\n",
    "        sum_all_source_emp=sum([s['source_emp'] for s in site_stats])\n",
    "        raw_ind['walkable_housing']=sum([s['source_emp']*s['total_pop_rac'] for s in site_stats])/sum_all_source_emp\n",
    "        raw_ind['walkable_employment']=sum([s['source_pop']*s['total_employ_wac'] for s in site_stats])/sum_all_source_pop\n",
    "        raw_ind['walkable_healthcare']=sum([s['source_pop']*s['emp_naics_62'] for s in site_stats])/sum_all_source_pop\n",
    "        raw_ind['walkable_hospitality']=sum([s['source_pop']*s['emp_naics_72'] for s in site_stats])/sum_all_source_pop\n",
    "        raw_ind['walkable_shopping']=sum([s['source_pop']*s['emp_naics_44-45'] for s in site_stats])/sum_all_source_pop\n",
    "        \n",
    "        norm_ind={}\n",
    "        for ind_name in raw_ind:\n",
    "            norm_ind[ind_name]=self.score_ecdfs[ind_name](raw_ind[ind_name])       \n",
    "        return {'raw': raw_ind, 'norm': norm_ind}\n",
    "                  \n",
    "    def return_indicator(self, geogrid_data):\n",
    "        start_ind_calc=datetime.datetime.now()\n",
    "        zone_site_stats, grid_site_stats=self.aggregate_reachable_attributes_all_sources(geogrid_data)\n",
    "        new_ind=self.calculate_indicators(zone_site_stats + grid_site_stats)\n",
    "        \n",
    "        base_zone_site_stats, base_grid_site_stats=self.aggregate_reachable_attributes_all_sources()\n",
    "        base_ind=self.calculate_indicators(base_zone_site_stats)\n",
    "        \n",
    "        outputs=[]\n",
    "        for ind_name in new_ind['raw']:\n",
    "            outputs.append({'name': ind_name.replace('_', ' ').title(),\n",
    "                           'raw_value': new_ind['raw'][ind_name],\n",
    "                           'value': new_ind['norm'][ind_name],\n",
    "                           'ref_value': base_ind['norm'][ind_name]})\n",
    "        end_ind_calc=datetime.datetime.now()\n",
    "        \n",
    "        heatmap=self.compute_heatmaps(grid_site_stats)\n",
    "        post_url='https://cityio.media.mit.edu/api/table/update/'+self.table_name       \n",
    "        r = requests.post(post_url+'/access', data = json.dumps(heatmap))\n",
    "        print('Post heatmap: {}'.format(r))\n",
    "        end_hm_calc=datetime.datetime.now()\n",
    "        \n",
    "        print('Prox Ind: {}'.format(end_ind_calc-start_ind_calc))\n",
    "        print('Prox HM: {}'.format(end_hm_calc-end_ind_calc))\n",
    "        \n",
    "        return outputs\n",
    "      \n",
    "    def get_network_around_geom_buffered(self, geom):\n",
    "        \"\"\"\n",
    "        Creates a buffer around the geometry and downloads the graph for this area\n",
    "        \"\"\"\n",
    "        geom_projected=osmnx.projection.project_gdf(geom)\n",
    "        geom_projected_buffered=geom_projected.unary_union.buffer(self.buffer)\n",
    "\n",
    "        geom_projected_buffered_gdf=gpd.GeoDataFrame(geometry=[geom_projected_buffered], crs=geom_projected.crs)\n",
    "        geom_wgs_buffered_gdf=geom_projected_buffered_gdf.to_crs(geom.crs) \n",
    "        \n",
    "        return osmnx.graph.graph_from_polygon(geom_wgs_buffered_gdf.iloc[0]['geometry'], network_type='walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H=Handler(table_name=table_name)\n",
    "# print(H.table_name)\n",
    "\n",
    "# p=Proximity_Indicator()\n",
    "# p.link_table(table_name=table_name)\n",
    "\n",
    "# H.add_indicator(p)\n",
    "\n",
    "# p.load(state=st, table_name=table_name) \n",
    "\n",
    "# H.listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Density_Indicator(Indicator):\n",
    "    def load(self, state, table_name_x):\n",
    "        self.state=state\n",
    "        self.table_name_x=table_name_x\n",
    "#         self.requires_geometry=True\n",
    "        self.grid_cell_area=None\n",
    "#         self.init_geogrid()\n",
    "        if 'ALAND' in self.state.geom.columns:\n",
    "            self.state.geom['area']=self.state.geom['ALAND']\n",
    "        else:\n",
    "            self.state.geom['area']=self.state.geom['ALAND10']\n",
    "        self.get_overlap_geoids()\n",
    "        self.compute_base_score_distribution()\n",
    "                \n",
    "    def compute_base_score_distribution(self):\n",
    "        \"\"\"\n",
    "        computes ECDFs of the indicators across the baseline zones\n",
    "        the ECDFs are later used to nromalise indicators by finding the percentile rank of the updated site wrt\n",
    "        the baseline zones\n",
    "        \"\"\"\n",
    "        self.score_ecdfs={}\n",
    "        self.base_scores={}\n",
    "        self.base_scores['res_density']=self.state.geom.apply(lambda row: self.res_density(row), axis=1)\n",
    "        self.base_scores['emp_density']=self.state.geom.apply(lambda row: self.emp_density(row), axis=1)\n",
    "        self.base_scores['live_work_score']=self.state.geom.apply(\n",
    "            lambda row: self.get_live_work_score(row), axis=1)\n",
    "        \n",
    "        # Diversity\n",
    "        industry_columns=[col for col in self.state.geom.columns if 'emp_naics' in col]\n",
    "        res_income_columns=[col for col in self.state.geom.columns if 'res_income' in col]\n",
    "        \n",
    "        self.base_scores['industry_diversity']=self.state.geom.apply(\n",
    "            lambda row: self.get_diversity(row, species_columns=industry_columns), axis=1)\n",
    "        self.base_scores['income_diversity']=self.state.geom.apply(\n",
    "            lambda row: self.get_diversity(row, species_columns=res_income_columns), axis=1)\n",
    "        \n",
    "        for score in self.base_scores:\n",
    "#             plt.figure()\n",
    "#             plt.hist(self.base_scores[score])\n",
    "#             plt.title(score)\n",
    "            base_scores_no_nan=[x for x in self.base_scores[score] if x==x]\n",
    "            self.score_ecdfs[score]=ECDF(base_scores_no_nan)\n",
    "            \n",
    "    def get_overlap_geoids(self):\n",
    "        \"\"\"\n",
    "        find the geoids of the baseline zones which overlap with hthe geogrid\n",
    "        \n",
    "        \"\"\"\n",
    "        get_url='https://cityio.media.mit.edu/api/table/'+self.table_name_x\n",
    "        with urllib.request.urlopen(get_url+'/GEOGRID') as url:\n",
    "            geogrid=gpd.read_file(url.read().decode())\n",
    "\n",
    "        self.state.geom['copy_GEOID']=self.state.geom.index\n",
    "        grid_intersect_zones=gpd.overlay(geogrid, self.state.geom, 'intersection')\n",
    "        self.overlapping_geoids=grid_intersect_zones['copy_GEOID'].unique()\n",
    "        \n",
    "    def combine_site_attributes(self, geogrid_data=None):\n",
    "        \"\"\"\n",
    "        takes the attributes of the geogrid_data (new programming) and \n",
    "        the zones which overlap with the geogrid and (pre-existing programming)\n",
    "        aggregates them together to get the updated site stats\n",
    "        \"\"\"\n",
    "        stats_to_aggregate=['total_pop_rac', 'total_employ_wac', 'area']+[\n",
    "            col for col in self.state.geom.columns if (('naics' in col) or ('income' in col))]\n",
    "        temp_site_stats=dict(self.state.geom.loc[self.overlapping_geoids, \n",
    "                                                 stats_to_aggregate].sum())\n",
    "        if geogrid_data is not None:\n",
    "            side_length=self.get_table_properties()['cellSize']\n",
    "            type_def=geogrid_data.get_type_info()\n",
    "            agg_types=aggregate_types_over_grid(geogrid_data, side_length=side_length, type_def=type_def)\n",
    "            agg_naics=aggregate_attributes_over_grid(geogrid_data, 'NAICS', side_length=side_length, type_def=type_def, digits=2)\n",
    "            agg_lbcs=aggregate_attributes_over_grid(geogrid_data, 'LBCS', side_length=side_length, type_def=type_def, digits=1)\n",
    "            \n",
    "            # update total residential and total employment\n",
    "            add_emp=sum(agg_naics.values())\n",
    "            if '1' in agg_lbcs:\n",
    "                add_res=agg_lbcs['1']\n",
    "            else:\n",
    "                add_res=0    \n",
    "            temp_site_stats['total_pop_rac']+=add_res\n",
    "            temp_site_stats['total_employ_wac']+=add_emp\n",
    "            \n",
    "            # update employment for each NAICS code\n",
    "            for col in temp_site_stats:\n",
    "                if 'naics' in col:\n",
    "                    col_naics_codes=col.split('naics_')[1].split('-')\n",
    "                    for code in col_naics_codes:\n",
    "                        if code in agg_naics:\n",
    "                            temp_site_stats[col]+=agg_naics[code]  \n",
    "                            \n",
    "            # update residential types\n",
    "            if 'Residential Low Income' in agg_types:\n",
    "                temp_site_stats['res_income_u1250_rac']+=agg_types['Residential Low Income']\n",
    "            if 'Residential Med Income' in agg_types:\n",
    "                temp_site_stats['res_income_1251-3333_rac']+=agg_types['Residential Med Income']\n",
    "            if 'Residential High Income' in agg_types:\n",
    "                temp_site_stats['res_income_3333+_rac']+=agg_types['Residential High Income']          \n",
    "        return temp_site_stats\n",
    "\n",
    "    \n",
    "    def calculate_indicators(self, site_stats):\n",
    "        raw_ind={}\n",
    "        raw_ind['res_density']=self.res_density(site_stats)\n",
    "        raw_ind['emp_density']=self.emp_density(site_stats)\n",
    "        raw_ind['live_work_score']=self.get_live_work_score(site_stats)\n",
    "        \n",
    "        industry_columns=[col for col in self.state.geom.columns if 'emp_naics' in col]\n",
    "        res_income_columns=[col for col in self.state.geom.columns if 'res_income' in col]\n",
    "        \n",
    "        raw_ind['industry_diversity']=self.get_diversity(site_stats, species_columns=industry_columns)\n",
    "        raw_ind['income_diversity']=self.get_diversity(site_stats, species_columns=res_income_columns)\n",
    "               \n",
    "        norm_ind={}\n",
    "        for ind_name in raw_ind:\n",
    "            norm_ind[ind_name]=self.score_ecdfs[ind_name](raw_ind[ind_name])       \n",
    "        return {'raw': raw_ind, 'norm': norm_ind}\n",
    "                  \n",
    "    def return_indicator(self, geogrid_data):\n",
    "        start_ind_calc=datetime.datetime.now()\n",
    "        new_site_stats=self.combine_site_attributes(geogrid_data=geogrid_data)\n",
    "        new_ind=self.calculate_indicators(new_site_stats)\n",
    "        \n",
    "        base_site_stats=self.combine_site_attributes(geogrid_data=None)\n",
    "        base_ind=self.calculate_indicators(base_site_stats)\n",
    "        \n",
    "        outputs=[]\n",
    "        for ind_name in new_ind['raw']:\n",
    "            outputs.append({'name': ind_name.replace('_', ' ').title(),\n",
    "                           'raw_value': new_ind['raw'][ind_name],\n",
    "                           'value': new_ind['norm'][ind_name],\n",
    "                           'ref_value': base_ind['norm'][ind_name]})\n",
    "        end_ind_calc=datetime.datetime.now()\n",
    "        print('Dens Ind: {}'.format(end_ind_calc-start_ind_calc))\n",
    "#         print(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def res_density(obj):\n",
    "        \"\"\"\n",
    "        input can be a row if the baseline geodataframe\n",
    "        or a dict representing a dynamic site\n",
    "        \"\"\"\n",
    "        if obj['area']>0:\n",
    "            return obj['total_pop_rac']/obj['area']\n",
    "        return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def emp_density(obj):\n",
    "        \"\"\"\n",
    "        input can be a row if the baseline geodataframe\n",
    "        or a dict representing a dynamic site\n",
    "        \"\"\"\n",
    "        if obj['area']>0:\n",
    "            return obj['total_employ_wac']/obj['area'] \n",
    "        return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_live_work_score(obj):\n",
    "        if obj['total_pop_rac'] > obj['total_employ_wac']:\n",
    "            return obj['total_employ_wac']/obj['total_pop_rac']\n",
    "        else:\n",
    "            return obj['total_pop_rac']/obj['total_employ_wac']\n",
    "     \n",
    "    @staticmethod\n",
    "    def get_diversity(obj, species_columns):\n",
    "        species_counts=[obj[col] for col in species_columns]\n",
    "        diversity=0\n",
    "        pop_size=sum(species_counts)\n",
    "        if ((len(species_counts)>1) and (pop_size>0)):        \n",
    "            for count in species_counts:\n",
    "                pj=count/pop_size\n",
    "                if not pj==0:\n",
    "                    diversity+= -pj*math.log(pj)\n",
    "            equitability=diversity/math.log(len(species_counts))\n",
    "            return equitability\n",
    "        else:\n",
    "            return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialise GEOGRID: <Response [200]>\n",
      "Initialise GEOGRIDDATA: <Response [200]>\n",
      "Downloading state outlines\n",
      "Getting geometry (block_group) for state: California\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/GoogleDrive/My Drive/OpenCity/OpenCity.py:74: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroids=self.geom['geometry'].centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting by urbanized areas\n",
      "Getting WAC data from https://lehd.ces.census.gov/data/lodes/LODES7/\n",
      "\t Formatting WAC data\n"
     ]
    }
   ],
   "source": [
    "properties=init_geogrid(table_name)\n",
    "state_fips=identify_state(properties)\n",
    "\n",
    "st=OpenCity.US_State(state_fips, year=2018, geom_type=geom_type)\n",
    "st.get_geometry()\n",
    "st.remove_non_urban_zones()\n",
    "st.get_lodes_data( include=['wac', 'rac'])\n",
    "st.add_lodes_cols_to_shape()\n",
    "st.geom.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=Handler(table_name=table_name)\n",
    "print(H.table_name)\n",
    "\n",
    "d=Density_Indicator()\n",
    "d.link_table(table_name=table_name)\n",
    "\n",
    "p=Proximity_Indicator()\n",
    "p.link_table(table_name=table_name)\n",
    "\n",
    "H.add_indicator(d)\n",
    "H.add_indicator(p)\n",
    "\n",
    "d.load(state=st, table_name_x=table_name)\n",
    "p.load(state=st, table_name=table_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# geogrid_data=H.get_geogrid_data()\n",
    "# zone_site_stats, grid_site_stats=p.aggregate_reachable_attributes_all_sources(geogrid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.geogrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# osmnx.get_nearest_node(\n",
    "#             self.ref_G, self.state.geom['x_centroid'][0], self.state.geom['y_centroid'][0], return_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.overlapping_geoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.zone_to_reachable['060816119001']['zones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.zone_to_reachable['060816119001']['cells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self=p\n",
    "# sub_graph=self.make_ego_graph_around_geometry(self.geogrid.iloc[0])\n",
    "# sub_graph_nodes=sub_graph.nodes(data=False)\n",
    "# reachable_zones= list(self.state.geom.loc[self.state.geom['central_node'].isin(\n",
    "#     list(sub_graph_nodes))].index.values)\n",
    "\n",
    "# reachable_grid_cells=list(self.geogrid.loc[self.geogrid['central_node'].isin(\n",
    "#     list(sub_graph_nodes))].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.state.geom.loc[self.state.geom['central_node'].isin(list(sub_graph_nodes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.ref_G.nodes[4074983959]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4074983959 in sub_graph_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# osmnx.plot.plot_graph(sub_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for score in p.base_scores:\n",
    "#     plt.figure(figsize=(9,2))\n",
    "#     min_score, max_score=min(p.base_scores[score]), max(p.base_scores[score])\n",
    "#     _=plt.hist(p.base_scores[score], bins=[min_score+(max_score-min_score)*(x/100) for x in range(100)])\n",
    "#     plt.title(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:shapely]",
   "language": "python",
   "name": "conda-env-shapely-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
